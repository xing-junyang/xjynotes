# 评估的基础知识

**评估**是设计过程的组成部分之一。一般来说，评估是系统化的**数据搜集**过程。用户在和**界面草图、原型或实际开发的软件（可运行系统）**进行交互的过程，开发者应当收集关于**系统的可用性**和**用户体验**方面的信息，从而改善其设计。

企业需要好的设计，同时也需要方法来评价和指导好的设计；用户也期望一个令人愉悦和感到参与感的系统。这就是评估的桥梁作用。例如，我们可以从用户是否能够找到相应的菜单项、图像是否起到了吸引用户的作用、产品是否引人入胜等等。近日在华为体验时，我们就被邀请去对新一代 `Harmony Next` 的云服务进行了体验，并给出了相应的意见。这就是对实际开发的软件进行交互后所得出的用户反馈。华为的相关产品经理也听取了我们的意见，相当于收集了用户体验方面的信息。

例如，如果我们希望对云服务进行评估，我们可以在以下方面进行：

- 人们是否可以轻易地找到云服务的入口，并对其进行配置？
- 人们是否可以区分本地文件的上传状态？
- 人们是否在大多数场景下都可以使用云服务？
- 当多台设备同时使用同一账户的云服务时，如何解决各个设备本地与云端文件的冲突问题？

需要注意的是，邀请用户进行评估的目的不是设法理解用户，而是评估**特定用户在一个特定的环境背景下如何使用一个系统来执行一个特定的任务**。也就是说，评估不是用户心理学，而是有成体系的目标和定量分析。

有些时候，评估的**场地**和**时机**是比较容易被忽略的点，但是当评估特定的对象时，它们的选择是重要的。例如场地方面，智能手机布局的评估应当在实验室或者会议室进行，因为这些场地可以提供必要条件系统地检查产品是否满足用户的需求；而对于小孩子的玩具评估，则应当采取实地的场景进行评估，这样会让涉众更加放松自然。至于时机方面，如果研发新产品，那么就会投入大量的时间进行市场调研、需求设计、草图和故事图版的设计，然后通过评估对产品和需求的一致性进行检验，这就是**形成性评估**；而评估已完成产品成功与否则被称为**总结性评估**。形成性评估主要的目的是**调整和完善设计**，而总结性评估的主要目的是**确定产品需要改进的方面**。

## 评估原则

如果希望制定有效可行的评估，就应当遵循一些好的评估原则：

- **评估应当依赖产品的用户**：与专业技术人员的水平和技术无关；
- **评估与设计应当结合进行**：如果总是靠用户最后对产品的一两次评估，是不能完全反映出软件的可用性的，需要反复迭代。
- **评估应该在用户的实际工作任务和操作环境下进行**：这样才能根据用户完成任务的结果进行客观的分析和评估。
- **评估要选择有广泛代表性的用户**：参加测试的人必须有代表性，否则就是无用功。

## 评估范型

评估有一些可供参考的范型，包括**快速评估、可用性测试、实地研究**和**预测性评估**。

### 快速评估

设计人员**非正式地**、**快速地**向用户或顾问了解反馈信息，用来证实构思是否符合用户的需要。这一评估方式可以在任何阶段进行，并且强调快速了解，而不是仔细的记录和发现，因此，最终得到的数据经常是叙述性的而非形式化的。

这一方法广泛用于设计网站、简单的小程序等简易项目。往往，用户的需求不算庞大，开发的工作也不算繁杂。它的最大特点就是**快速**。

（关键评估技术因素：**可以在周期中的任何位置** **响应及时** **所需资源少**）

### 可用性测试

可用性测试用来评测**典型用户执行典型任务时的情况**。这一方法提供对用户执行情况的**量化**表示，例如，可以统计用户的出错次数、完成任务的时间等。这一过程是在评估人员的密切控制之下进行的。但是它也有某些缺点，如**测试用户的数量往往过少**，并且**不适合进行细致的统计分析**。

（关键评估技术因素：**定量数据**）

### 实地研究

在**自然工作环境**进行的评估方法，便于理解用户的实际工作情形以及技术对它们的影响。这一方法可以更贴近实际地去**确定产品需求、评估现有技术的应用和促进新技术的引入**。但是缺点也相对比较明显：用户的选择是自由的，**很难预测即将发生和出现的情况**，并且想要**对受试者完全不影响是很难的**。

（关键评估技术因素：**工作环境** **对用户的干扰小**）

### 预测性评估

研究性人员通过想象或对界面的使用过程进行建模，而用户可以不在场。多用于比较相同应用不同界面的原型法，例如使用 $\mathrm{Fitts}$ 定律预测使用设备定位目标的时间。

（关键评估技术因素：**主观** **所需资源少**）

## 人机交互的实证研究方法

**实践是检验真理的唯一标准**，在人机交互上也不例外。而人机交互的一次实验，通常从研究假设开始。

### 研究假设

研究假设是一种**可以**通过实证研究直接检验的**精确**问题陈述，它奠定了一个实验的基础。在人机交互中，研究假设一般分为两种，即**零假设**和**备择假设**。零假设的内容通常是在不同实验条件**不会产生差异**的；而备择假设往往是与零假设的一个**相反的陈述**。实验的目标通常是**找到统计学证据来反驳或否定零假设，来支持备择假设**。零假设和备择假设一般是**成对**出现的，但可以**同时研究多对**零假设和备择假设。

例如，某个网站的开发人员试图弄清楚某个组件应当使用下拉菜单还是弹出菜单。他可以设计零假设为“**下拉菜单和弹出菜单在定位页面的时间开销上没有差异**”，而备择假设就应当是“**下拉菜单和弹出菜单在定位页面的时间开销上存在差异**”。他还可以设计零假设“**下拉菜单和弹出菜单在用户满意度评价上没有差异**”，和备择假设“**下拉菜单和弹出菜单在定位页面的时间开销上存在差异**“。

好的假设对一次成功的实验起到了至关重要的作用。假设应当是**清晰的，集中的**（每次只关注一个小问题），并且应当**明确说明实验的条件**。

一个定义明确的假设会明确说明研究的**因变量**和**自变量**。因变量是**研究者感兴趣的结果或效果**，它通常依赖于受试者的行为以及自变量的变化。常见的因变量有**任务完成时间、速度、准确性**等。自变量是可能**引发因变量变化**且**与受试者行为无关**的部分。常见的自变量有**年龄、性别、身高、输入设备、设计（如字体大小、背景色、菜单形态）**等。研究者希望**可复现地**了解自变量的变化是否以及如何引起因变量的变化。

### 实验构成

**实验条件**：指我们需要比较的不同技术、设备和程序。是实验开展的基础设施。**实验条件的设定和之前的研究假设相关。**

**实验单位**：指我们应用实验条件的对象。通常为具有特定特征的受试用户。

**分配方式**：指将试验单位分配到不同实验条件的方式。一般尽可能采取**随机化**的方式。

### 实验设计

真正的实验需要进行以下方面的设计：

- 以至少一个**可检验**的、**定义明确**的研究假设为基础，并尝试去验证它。
- 通常至少要有两组实验条件来形成对照，并用**定量的**分析来测量因变量的结果。
- 需要借助各种**统计显著性检验**来对结果进行分析，说明结果的价值。这一过程旨在消除偏差和偶然性。
- 实验在不同的时间、地点和参与者下是可以复现的。

在实验设计时，还需要设计实验的结构，常见的有以下的方面：

- **自变量数**：实验中应当研究一个还是多个自变量。如果只研究一个自变量，可以采用**基本设计**的方式；而如果研究多个自变量，可以使用**析因设计**的方式。析因顾名思义即分析各个自变量之间的“因”，即联系。
- **自变量的取值**：每个自变量的取值是如何的。可以据此分析应当使用**组间设计**、**组内设计**还是**裂区设计**。组间设计指每个参与者只暴露在**一种**实验条件下，它避免了学习效应和疲劳问题，但同时也减少了采样的数量；组内设计与组间设计刚好相反。学习和疲劳是不可避免的，只能去平衡。


### 多个自变量的实验

当一个实验调查一个以上的自变量或因素时，广泛采用**析因分析**。析因分析可以同时调查所有自变量的影响以及多个变量之间的交互影响。假设每个变量的取值为 $V_a$，那么应当设计的条件个数为 $\Pi_{a=1}^{n} V_a$。

例如，我们可以比较使用三种类型键盘（QWERTY键盘、DVORAK键盘和字母键盘）时的打字速度，且调查不同的任务（写作和抄写）对打字速度的影响，结果可以输出为 $3\times 2$ 列联表。

当析因研究中既有**组间成分**和**组内成分**，称为**裂区设计**。




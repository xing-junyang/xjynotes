# 机器学习简述

::: warning 写在最前

机器学习是基于多学科交叉融合的新兴学科，而这当中的基石就是**数学**。因此，如果希望更好地理解机器学习的来龙去脉，而非只是死记硬背各种算法，那么就必须涉及到的数学知识有基本的了解。

简单来说，机器学习的数学基础主要包括**线性代数**、**概率论**、**统计学**以及**优化理论**等。读者应当具有大学本科理工科专业所具备的数学知识。此外，笔者在学习的过程中发现，在这一基础上还需要了解一些特定方向的数学知识。而对于这一部分知识，可以在[数学基础补充](/机器学习/数学基础补充.md)这一文章中找到简单的概述。

:::

如果有人问，机器学习是什么？有人会说，是那些最先进的技术，比如**深度学习**、**神经网络**、**自然语言处理**、**计算机视觉**等等。但是，这些只是机器学习的一部分实践。机器学习是数据、模型和学习三个层面的交叉学科。我们希望通过下面的内容来简单介绍一些机器学习的**基本概念**和**关键思想**。

## 机器学习是什么？

**学习是一个蕴含特定目的的知识获取过程**。其内部表现为新知识的不断建立和修正，外部表现为性能改善。同时，学习既需要外部的材料，也需要内部的推理与记忆的过程。

（广义的机器学习）**任何通过数据训练的学习算法都属于机器学习**。

**机器学习整体上分为三个层面**：**数据层面**、**模型层面**和**学习层面**。

<div style="display: flex; align-items: center; justify-content: center; flex-direction: column">
<img src='/image/Screen Shot 2024-09-08 at 9.29.19 PM.png' alt="" style="width:75%;"></img>
</div>

### 数据层面

数据的类型和特点主要有以下几点，在选择机器学习模型上要首先对数据进行考量：

- 静态和动态
- 小数据和大数据
- 同质和异质：数据类型上的异质性，如结构化数据和非结构化数据；
- 单态和多态
- 小类数和大类数：如二分类（性别）、多分类（个体）等；
- 带噪和缺失数据：如标签带有噪音等；
- 高维数据和非数值数据：如字符串、图像等；

机器学习的成效对于数据与选择的学习方式和模型有强敏感性。在所有时候，都要对具体数据的类型和特点进行分析，而不能硬搬硬套算法，这是机器学习的基本原则。

### 模型层面


- 任务：**分类、回归、聚类、降维、关联规则挖掘等**
- 形式上：**线性模型/非线性模型**
- 体系：**浅层、深度、递归等**

### 学习层面

指具体的学习方法（或称算法），例如下面的：
- 经典学习方法：如归纳学习、类比学习、解释学习、决策树、贝叶斯分类器、聚类等；
- 现代学习方法：监督学习/无监督学习、集成学习、强化学习等；
- 混合学习方法

学习方法的关系：深度学习 $\in$ 表示学习 $\in$ 机器学习 $\in$ 人工智能

## 机器学习的理论基础

最重要的理论模型：$\mathrm{PAC}$​ **概率近似正确**。它定义了训练样本数、错误率之间的数学关系。简单地讲，就是说对于一个学习器，只要它有足够多的训练样本，那么它就能以很高的概率得到一个接近真实的模型。它是可学习性理论的基础。

$$
P(|f(\mathbf{x})-y|\le \epsilon) \ge 1-\delta
$$

而经典机器学习一般以**感知**（获取数据）、**预处理**、**特征抽取**、**特征选择**和**推理预测**为主要内容。现代的机器学习的流程则更加复杂多变，如**深度学习**、**强化学习**等。

## 基本术语

- **数据集**：训练集、测试集（可能还有验证集）。
- **示例、样例、样本**：关于一个事件或对象的描述。即属性空间表的一**行**。
- **属性、特征**：关于事件或对象在某方面的表现或性质。即属性空间表的一**列**。
- **属性空间、样本空间、输入空间**：由各属性张成的空间。
- **标记**：关于示例结果的信息。所有标记的集合称为**标记空间**或**输出空间**。
- **特征向量**：一个**示例**在**属性空间**中对应的坐标向量。
- **模型**：学习算法在给定数据和参数空间上的实例化。
- **假设**（学得模型对应的某种规律）、**真相**（实际中的规律）、**学习器**（即模型）。
- **分类、二分类和回归**：分类输出是离散值，二分类的输出是两个类别（正类和反类），回归的输出是连续值。
- **监督学习/无监督学习**：由训练资料中学到或建立一个模式，然后依此模式推测新的实例。监督学习是指学习过程中有监督信号（标记），无监督学习则没有。
- **聚类**：将训练集中的示例根据一种潜在的概念分为若干组。一般来说，聚类中的数据集不带有标记，而是在学习过程中自行推断类别。
- **泛化**能力：学得模型适用于新样本的能力。

::: tip 一个实际的例子

我们希望根据房屋的**面积**（平方英尺）和**房龄**（年）来估算**房屋价格**（美元）。 为了开发一个能预测房价的模型，我们需要收集一个真实的数据集。 这个数据集包括了房屋的销售价格、面积和房龄。 在机器学习的术语中，该数据集称为**训练数据集**（training data set） 或**训练集**（training set）。 每行数据（比如一次房屋交易相对应的数据）称为**样本**（sample）， 也可以称为**数据点**（data point）或**数据样本**（data instance）。 我们把试图预测的**目标**（比如预测房屋价格）称为**标签**（label）或**目标**（target）。 预测所依据的**自变量**（面积和房龄）称为**特征**（feature）或**协变量**（covariate）。

<div style="font-size: 12px; color: gray;">来源于此文章，可参考：<a href="https://zh.d2l.ai/chapter_linear-networks/linear-regression.html#id2">DIVE INTO DEEP LEARNING (zh.d2l.ai)</a></div>

:::

## 归纳偏好

机器学习算法在学习过程中对某种类型假设的偏好。偏好是必然存在的。在实际模型选择和训练中，即要考虑算法的归纳偏好，还要防止**过拟合**。

一般原则：**奥卡姆剃刀**。这是一个科学的原则，也是一种哲学思想。它的主要内容即在所有可能的解释中，最简单的解释最有可能是正确的。我们倾向于认为，这一世界的本质是简单的。在机器学习中，我们也倾向于认为，简单的模型比复杂的模型更有效。

另一个理论模型：$\mathrm{NFL}$ **没有免费的午餐**。一个算法若在某些问题上比另一个算法好，那就必然存在一些问题让这个算法没有那个算法好。也就是说，**没有一个算法能在所有问题上表现最好（免费的午餐）**。

## 统计学基本概念

**简单统计概念**

- 众数、中位数、平均数、方差、极差等
- **协方差** $\mathrm{cov}(X,Y)=E((X-E(X))(Y-E(Y)))$
- 协方差矩阵 $[\mathrm{cov}(X_i,X_j)]_{m\times n}$

**距离度量函数**。如两个样本向量 $x_i, x_j \in \mathbb{R}^d$，则它们的各个函数计算方法如下

- 欧式距离 $d(x_i, x_j)=||x_i-x_j||_2=\sqrt{(x_i- x_j)^T(x_i- x_j)}$
- 余弦相似性（类似角度）$s(x_i, x_j)=\frac{x_i^Tx_j}{||x_i||\cdot||x_j||}$
- 曼哈顿距离 $d(x_i, x_j)=||x_i-x_j||_1$
- 切比雪夫距离 $d(x_i, x_j)=||x_i-x_j||_{\infty}$
- 马氏距离 $d_M(x_i, x_j)=\sqrt{(x_i- x_j)^TM(x_i- x_j)}$

**函数凸凹性**质、凸优化（可以看《凸优化》这本书入门）

**高斯分布**

**概率**

::: tip 从概率框架的角度对机器学习方法分类

- 生成式模型：估计 $P(x|y=i)$ 和 $P(y=i)$，然后通过贝叶斯公式计算 $P(y=i|x)$。
- 判别式模型：直接估计 $P(y=i|x)$。不假设概率模型，直接求一个把各类分开的边界。

:::

## 新型机器学习发展趋势

- 模型层面：**大模型+领域知识，大模型+多模态信息/结构信息，小模型+模型蒸馏+量化**
- 优化层面：**在线/增量学习、分布式学习+异步优化、加速现有算法**
- 数据层面：**大数据（带噪声数据学习、多模态数据学习）、小数据（数据提炼蒸馏）**

## 一些机器学习的例子

- $\mathrm{AlphaGo}~(2015)$​​
- $\mathrm{CLIP}~(2022)$​  文本+图像的多模态大模型，通过文本来索引图像
- $\mathrm{DALL\cdot E}(2021)$ 通过文本来输出图像
- $\mathrm{AlphaFold}~(2021)$ 根据氨基酸序列进行蛋白质结构预测
- $\mathrm{AlphaCode}~(2022)$ 竞赛程序代码生成
- $\mathrm{GPT-3}~(2022)$ 
- $\mathrm{ChatGPT}~(2022)$​ 
- $\mathrm{GPT-4o}~(2024)$​ 更自然的人机交互
- $\mathrm{Sora}~(2024)$ 较强的物体一致性、连续性，初步理解世界知识